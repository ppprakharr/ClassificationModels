{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPi9CQIX5o3AwihSIZLvyPN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppprakharr/ClassificationModels/blob/main/MRI_Scan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "AFHaCfNm82gU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_credentials = json.load(open(\"kaggle.json\"))\n",
        "os.environ['KAGGLE_USERNAME']=kaggle_credentials['username']\n",
        "os.environ['KAGGLE_KEY']=kaggle_credentials['key']"
      ],
      "metadata": {
        "id": "dN34N_2u8EOd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxRfssjH76eu",
        "outputId": "d17901ef-63f3-4b1d-e670-46b962874449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading brain-tumor-mri-dataset.zip to /content\n",
            "100% 148M/149M [00:07<00:00, 22.0MB/s]\n",
            "100% 149M/149M [00:07<00:00, 20.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unzipping\n",
        "zip_path='/content/brain-tumor-mri-dataset.zip'\n",
        "from zipfile import ZipFile\n",
        "with ZipFile(zip_path,'r') as zip:\n",
        "  zip.extractall()\n"
      ],
      "metadata": {
        "id": "1MkMZLd_8gOT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(1)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(1)\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1)"
      ],
      "metadata": {
        "id": "UqZRx6DF9kEs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnWT-Eqx_Hio",
        "outputId": "99e2d2aa-410d-4730-8474-e8a0cf4952d3"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "brain-tumor-mri-dataset.zip  kaggle.json  sample_data  Testing\tTraining\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers,models"
      ],
      "metadata": {
        "id": "y_K8uugN_Iye"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/content/Training')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMjrQS0b_UP6",
        "outputId": "d7f18a30-4b56-4b81-a6c2-3cbd65ab05ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir('/content/Training/')[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjZiduae_d2-",
        "outputId": "8121374b-a6ab-4433-8195-b4e5ad257ac8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pituitary', 'meningioma', 'glioma', 'notumor']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/content/Training/notumor')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiFR629e_ipY",
        "outputId": "ebb86e7e-086e-4574-a813-4678d39694d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir('/content/Training/notumor')[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku-_Fgp0_s4j",
        "outputId": "518396ab-9bad-4ca6-bcaa-2587086d141f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tr-no_0937.jpg', 'Tr-no_0870.jpg', 'Tr-no_0852.jpg', 'Tr-no_1555.jpg', 'Tr-no_1327.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#base dir\n",
        "base_dir = '/content/Training/'"
      ],
      "metadata": {
        "id": "SWqmoilZ_7pA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image data generator\n",
        "data_gen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "WQ6HHycIG-qi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size=224\n",
        "batch_size=32"
      ],
      "metadata": {
        "id": "M_pV3-ZIOOca"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train generator\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(img_size,img_size),\n",
        "    batch_size=batch_size,\n",
        "    subset='training',\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQxisFw_JYGg",
        "outputId": "a530545e-646e-4bae-d36e-89648e8fd530"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4571 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test generator\n",
        "validation_generator = data_gen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(img_size,img_size),\n",
        "    batch_size=batch_size,\n",
        "    subset='validation',\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV_tFmPQPKlQ",
        "outputId": "2bade923-22c0-4837-a9fa-4a6a779df629"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1141 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(img_size,img_size,3)))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256,activation='relu'))\n",
        "model.add(layers.Dense(train_generator.num_classes,activation='softmax'))"
      ],
      "metadata": {
        "id": "fOsmjLKcPN8_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKBUL8HJPUwp",
        "outputId": "24c32a88-c67a-4610-9917-108052c0bf53"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 111, 111, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 111, 111, 32)      0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 109, 109, 64)      0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 54, 54, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 186624)            0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               47776000  \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 47796420 (182.33 MB)\n",
            "Trainable params: 47796420 (182.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "atD2QqF8PYth"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples//batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples//batch_size,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM2G0vLbP4wF",
        "outputId": "54a3be39-39fd-4041-e6db-87f448d22907"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "142/142 [==============================] - 23s 117ms/step - loss: 1.8668 - accuracy: 0.5739 - val_loss: 1.0500 - val_accuracy: 0.6125\n",
            "Epoch 2/10\n",
            "142/142 [==============================] - 16s 109ms/step - loss: 0.4701 - accuracy: 0.8244 - val_loss: 0.9192 - val_accuracy: 0.6384\n",
            "Epoch 3/10\n",
            "142/142 [==============================] - 16s 110ms/step - loss: 0.2534 - accuracy: 0.9039 - val_loss: 0.7502 - val_accuracy: 0.7268\n",
            "Epoch 4/10\n",
            "142/142 [==============================] - 16s 110ms/step - loss: 0.1400 - accuracy: 0.9511 - val_loss: 0.8157 - val_accuracy: 0.7161\n",
            "Epoch 5/10\n",
            "142/142 [==============================] - 16s 109ms/step - loss: 0.0739 - accuracy: 0.9731 - val_loss: 0.8995 - val_accuracy: 0.7509\n",
            "Epoch 6/10\n",
            "142/142 [==============================] - 16s 111ms/step - loss: 0.0501 - accuracy: 0.9841 - val_loss: 1.0029 - val_accuracy: 0.7750\n",
            "Epoch 7/10\n",
            "142/142 [==============================] - 15s 108ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 1.0746 - val_accuracy: 0.7589\n",
            "Epoch 8/10\n",
            "142/142 [==============================] - 16s 113ms/step - loss: 0.0309 - accuracy: 0.9907 - val_loss: 1.1253 - val_accuracy: 0.7723\n",
            "Epoch 9/10\n",
            "142/142 [==============================] - 16s 110ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.9147 - val_accuracy: 0.7821\n",
            "Epoch 10/10\n",
            "142/142 [==============================] - 16s 112ms/step - loss: 0.0261 - accuracy: 0.9916 - val_loss: 0.9631 - val_accuracy: 0.7723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "CSWQJGjTP7jM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y-gAmDxkEou3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename='mriScanModel.sav'\n",
        "pickle.dump(model,open(filename,'wb'))\n",
        "mri = pickle.load(open(filename,'rb'))"
      ],
      "metadata": {
        "id": "zRkVmpdyhzMb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vnGqLw1riwOC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}